---
title: Decentralizing NFT.Storage
author: David Choi, Mikeal Rogers
description: The future evolution of NFT.Storage, from "permanence" to DAOification.
thumbnail: https://user-images.githubusercontent.com/22168118/146547661-afddfed5-d26e-49e2-8ff1-c32e8ccb7bc1.png
date: Jan 20, 2022
tags:
  - ipfs
  - filecoin
  - permanence
  - DAO
---

# Decentralizing NFT.Storage

NFT.Storage is already one of the easiest services to store NFT data on a decentralized network. We discuss our philosophy behind running this service today, and what's in store in the near future to eliminate the need for us or any single entity to provide persistent off-chain storage for NFTs.

## The Tragedy of the Commons

We know that NFTs are a groundbreaking technology in proving ownership of digital assets. Where they really shine is with assets that have value outside the domain of any single actor. For instance, if an item in a private company’s game is only good in that game, it doesn’t really matter whether that item is an NFT or not - that company can ultimately decide who owns that item or what it does. But if it’s an item in a metaverse spanning across ecosystems, then it’s super important that the item is an NFT, since there is now a single source of truth for ownership (a blockchain) that no one actor can modify without the owner’s private keys.

Currently, NFTs generally point to off-chain data (like images, videos, etc.) because of technological constraints for writing data on-chain (it’s expensive to write an entire image onto a blockchain). Ideally, this pointer is an [IPFS](https://ipfs.io/#how) URL, which is a [unique identifier](https://nft.storage/blog/post/2021-12-14-storage-layer-maximalism/) for a piece of data, universally compatible with any storage layer. Once it’s in an NFT, it’s an immutable reference to the content itself, and the content associated with the NFT can’t be changed or rugged by anybody. But in a situation where an NFT is repeatedly bought and sold, who is responsible for ensuring this off-chain data is available to the next buyer, or onlookers? Part of this responsibility undoubtedly falls on the buyer themselves, who should always always download a copy of the NFT for them to preserve themselves (which is not in the education and culture around NFTs today). However, the NFT still needs to be hosted and made available for this to happen. Currently, there’s no trustless (or in the vast majority of cases, even legal) mechanism to enforce this.

<blockquote class="twitter-tweet"><p lang="en" dir="ltr">I just pulled the rug at my NFT collection on <a href="https://twitter.com/opensea?ref_src=twsrc%5Etfw">@opensea</a> . Nobody got hurt.<br />It is pretty easy to change the jpg, even if it does not belong to me or it is on auction. I am the artist, my decision, right?<br />A thread from somebody making his living with art irl about the value of NFTs. <a href="https://t.co/LNAZqPpDMZ">[pic.twitter.com/LNAZqPpDMZ](http://pic.twitter.com/LNAZqPpDMZ)</a></p>— neitherconfirm (@neitherconfirm) <a href="https://twitter.com/neitherconfirm/status/1369285946198396928?ref_src=twsrc%5Etfw">March 9, 2021</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<p style={{ textAlign: 'center', fontStyle: 'italic', marginBottom: 20, fontSize: 14 }}>
  Rug pulls are a pretty common problem when using HTTP URLs, but issues around incentives for who is responsible for hosting NFT data go beyond this.
</p>

To solve this problem, the off-chain data needs to be stored in decentralized, and, for most NFTs, storage with guaranteed accessibility for the useful lifetime of the NFT ([nothing is truly permanent](https://mikeal.notion.site/web3-data-permanance-0230072b594748ed9aa0c71ad331f289)!). There are situations where central entities can band-aid over this problem. For example, a marketplace is willing to host off-chain data for NFTs minted on their service because they might be afraid that not doing so will hurt their reputation. However, you can easily imagine scenarios where this is not satisfactory - without a decentralized way of preserving data, NFTs will fall short of their potential as a decentralized primitive.

For the remainder of this post, we discuss how [NFT.Storage](http://NFT.Storage) plans to use Filecoin (which provides provable and decentralized storage) and Web3 funding mechanisms (which enables multi-generational storage) to persist NFT data as a public good, even as NFT.Storage increasingly decentralizes itself out of the picture (even completely).

# The new frontier

Web3 unlocks a number of big paradigm shifts. One is around how [public goods are funded](https://fundingthecommons.io/). With cryptographic guarantees and smart economics, new mechanisms to create and sustain common goods in a decentralized manner are blossoming, expanding the potential pie of public goods outside those that rely on governments, faith in private companies, and/or the philanthropy of a few.

![image](https://user-images.githubusercontent.com/11778450/150448351-b15c498c-643e-4b3a-8491-c4cc76969300.png)
<span style={{ display: 'block', textAlign: 'center', fontStyle: 'italic', marginBottom: 20, fontSize: 14 }}>
  A number of innovations using Web3 primitives are being explored to provide better support for funding common goods.
</span>

In addition to NFT.Storage’s mission to store the world’s NFTs, we believe that most NFTs should be treated as public goods. One can debate whether specific NFTs should go for millions of dollars, but the debate around artistic value is independent of the public value that NFTs as a primitive can unlock, making it an ideal candidate for public goods funding. In addition, given the decreasing cost of storage (potentially [converging to $0](https://jcmit.net/disk2015.htm)), the societal return on investment for this data storage will only continue to increase. NFT.Storage plans to use these public funding mechanisms in the context of the Filecoin network, which provides provable and economically incentivized storage for any duration of time.

That’s why NFT.Storage offers free storage for NFTs. Today, though the price of storage on the Filecoin network is ~free due to the economics of the [Filecoin Plus program](https://docs.filecoin.io/store/filecoin-plus/) (and expected to be for a while!), we also run our own infrastructure to get data onto Filecoin storage and to provide a fast user experience. However, from the beginning, we’ve been looking to make sure [NFT.Storage](http://NFT.Storage) can persist beyond the lifetime of a single individual or company - both any data stored via NFT.Storage and the service itself. The means by which we seek to accomplish this mission will change over time, but as this vision comes to fruition, the onboarding and persistence of data via NFT.Storage will become increasingly decentralized. For instance, there will be fewer and fewer costs to subsidize - and those that do remain will be funded as a public good.

We discuss some of these plans below!

# Data onboarding

## API Tier

A lot of what we’ve built in NFT.Storage is an API tier that makes the process of storing NFT data in IPFS and Filecoin simpler for developers. This helps them ensure that their data is publicly available when they want others to see their minted NFTs.

Since most browsers do not yet support IPFS natively, our HTTP APIs are centered around CIDs, with the client sending and receiving data that is easy to verify cryptographically. This eliminates the need for trust when using these APIs as on-boarding ramps for data onto IPFS and Filecoin.

![image](https://user-images.githubusercontent.com/11778450/150448398-f8c90d8a-66fe-415f-ac2f-23cbffa99861.png)
<span style={{ display: 'block', textAlign: 'center', fontStyle: 'italic', marginBottom: 20, fontSize: 14 }}>It’s easy to upload data via NFT.Storage’s API endpoint, and thanks to CIDs, also the uploaded data is verifiable!</span>

Further, we are seeing early adoption of IPFS in browsers (Brave, Opera Mobile, etc.) and with that adoption the need for these API services will continue to diminish (e.g., uploading data to Filecoin from the IPFS node in your browser with a click). In the meantime, our existing APIs will continue to operate, and we’ll continue to solve new problems with APIs until sufficient decentralized alternatives have matured.

## Niftysave

Something we’ve been doing for a while now is watching Ethereum’s mainnet and storing NFT metadata and assets we index from the chain on NFT.Storage - an effort we’ve been calling “niftysave.” We are now at a stage where we are scaling this system so that we can extend it to Solana, Tezos, and all other chains. We also hope to make this a community effort, harnessing the same community energy that [helped preserve HicEtNunc](https://medium.com/pinata/web3-data-portability-through-ipfs-saved-hicetnunc-724e3df2948d).

We see NFT.Storage as one of many actors playing an essential role in preserving and providing free and open access to humanity’s data. We are not the only actor interested in preserving this data, so our first task is to give others the ability to store and provide this data. This data in and of itself is powerful, as it gives each NFT a [content identifier](https://docs.ipfs.io/concepts/content-addressing/) (CID), even if the NFT itself is referencing an HTTP URL (provided that the data was still accessible when we attempted to scrape it). Then we’ll be working with other individuals, non-profits, public benefit organizations and even companies to preserve additional copies.

### Near-Term: Saving the NFTs

Indexing public blockchains is a bit harder than it may seem initially. We are highly confident that this will be easy, commoditized, and secure, at some point in the future as projects like The Graph and NFTPort mature and support more networks. But today, we take what we can get for indexing, and each network is proving to be a unique challenge in this regard.

What we are planning to do in 2022 is produce *our* storage set as a data structure that others can use to backup this data as well.

- This will be a simple [IPLD](https://ipld.io/) data structure that maps NFT addresses to metadata and asset CIDs.
- We will be regularly signing updates to this data structure and publishing them via IPNS.
- We will also write these [IPNS](https://docs.ipfs.io/concepts/ipns/) records into smart contracts so that contracts in each chain have a way to read the current state root from inside their smart contracts.
- Others can then help back up this data, and indexes can augment their datasets by providing the CID along with the rest of the NFT data.

### Long-Term: Saving the NFTs, but 100% decentralized

Eventually, we’d like for the entire pipeline that produces these IPLD data structures to be on-chain in smart contracts. In addition, once we have the upcoming [Filecoin Virtual Machine](https://fvm.filecoin.io/) (FVM), we can move the task of storing this data in Filecoin to secure contracts as well.

And as the Filecoin retrieval market develops, ensuring availability of all this data will be written into smart contracts that interact.

# Data retrieval

Tens of thousands of users, including some of the largest marketplaces, rely on NFT.Storage. As a result, we do what we need to in order to offer competitive performance to traditional web services. Given that browser adoption of IPFS has not yet reached critical mass, most users use [public IPFS gateways](https://ipfs.github.io/public-gateway-checker/), and we currently run an [IPFS Cluster](https://cluster.ipfs.io/) and other IPFS nodes to support faster retrieval via these gateways. For the near-term, we will optimize an HTTP endpoint called NFT.Storage Gateway (URL: nftstorage.link) that fetches from multiple public gateways, intelligently caches, and utilizes a CDN.

![image](https://user-images.githubusercontent.com/11778450/150448422-971b3320-27fd-4c90-b74c-2708779e0667.png)
<p style={{ textAlign: 'center', fontStyle: 'italic', marginBottom: 20, fontSize: 14 }}>
  Any operational public IPFS gateway can fetch data from NFT.Storage.
</p>

Users are always welcome to run their own IPFS nodes and access data that way. Though this would be less reliant on centralized infrastructure, this might not always be the most performant option. And like our storage APIs, since gateways use CIDs to retrieve content, retrieving from a gateway can be trustless - you *can* *verify* that the content you’re retrieving is correct.

We will continue to operate whatever caching layers and infrastructure that are necessary to meet user needs until comparable decentralized markets exist and have proven reliable. And we will fully support upgrades to decentralized retrieval solutions like Filecoin retrieval markets, giving more options for retrieval of data off of NFT.Storage.

# Data persistence

Given we’re moving to a world where NFTs can represent anything digital (tickets, game assets, art, etc.), it’s critical we design systems that both ensure public goods (such as storage), are well funded, and set up to store substantial volumes of data (PiB scale). 

We are using Filecoin for decentralized persistence because, as a protocol, it uniquely solves the latter component - ensuring that on fixed terms data is verifiably stored, at massive scale, at the cheapest price point. [ZK-proofs](https://filecoin.io/blog/posts/filecoin-zk-snarks-zero-knowledge-but-a-lot-of-zero-knowledge/) are critical here as they allows us to efficiently store a fixed number of copies and verifiably know when data is lost or taken offline. Storage providers are required to submit these proofs to the network proving they are storing the data during the duration of a storage “deal.”

Today, [NFT.Storage](http://NFT.Storage) monitors this manually, but with the upcoming [Filecoin Virtual Machine](https://fvm.filecoin.io/) (FVM), we can trustlessly automate these activities to ensure NFTs are *perpetually* stored. On the FVM, we will migrate our current processes to be entirely protocol-managed - a smart contract-based system can easily monitor the health of stored data, trigger repair deals when necessary, and automatically renew deals when they are approaching expiry, even if any individual party goes away.

![image](https://user-images.githubusercontent.com/11778450/150448432-47cccf5a-4ab7-40dd-b771-38c97583015f.png)
<p style={{ textAlign: 'center', fontStyle: 'italic', marginBottom: 20, fontSize: 14 }}>
  The Filecoin Virtual Machine will be a powerful tool in decentralizing services like NFT.Storage, providing the ability to democratize multi-generational storage of public data.
</p>

The FVM will also open up a lot of new opportunities to turn these renewal activities into a truly public good (e.g., as part of an ongoing endowment). With a [decentralized autonomous organization](https://en.wikipedia.org/wiki/Decentralized_autonomous_organization) (DAO), a community treasury can be established to fund storage - with on-chain activities (e.g. loans + DeFi) being used to generate revenue to perpetually fund storage on the Filecoin network (which is ~free today given [Filecoin Plus's](https://docs.filecoin.io/store/filecoin-plus/) economics, and with the DAO in position to hedge storage price changes moving forward). And, depending the DAO(s) is structured, we even plan to have direction of the product governed autonomously.

# Conclusion

At NFT.Storage, we are looking to provide amazing user experiences for off-chain NFT storage and retrieval for marketplaces, artists, collectors, and many others today, while bridging the gap to fully decentralized, multi-generational mechanisms for NFTs. We believe this will help fulfill the potential of NFTs as a groundbreaking technology.

Check out [NFT.Storage](http://NFT.Storage) today!
